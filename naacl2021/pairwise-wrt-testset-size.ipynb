{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm.notebook import tqdm, tqdm_notebook\n",
    "import json\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache(path, f):\n",
    "    if not os.path.exists(path):\n",
    "        result = f()\n",
    "        json.dump(result, open(path, 'wt'))\n",
    "        return result\n",
    "    else:\n",
    "        return json.load(open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(xs, df, true_means, trials=1000, group_name='system', score_name='score', ratio=-1):\n",
    "    # need to make sure all systems have about the same # of ex\n",
    "    # need to make sure that ratio is not very large\n",
    "    groups = df.groupby(group_name, as_index=False)\n",
    "    \n",
    "    ys = []\n",
    "    for x in tqdm(xs):\n",
    "        x = int(x * ratio) if ratio > 1 else x\n",
    "        data = []\n",
    "        \n",
    "        for i in range(0, trials):\n",
    "            simulated_test_set = groups.apply(lambda g: g.sample(n=x, replace=True).mean())\n",
    "            means = [ i for i in simulated_test_set[score_name] ]\n",
    "            \n",
    "            correct_pairs = 0\n",
    "            total_pairs = 0\n",
    "            for i, j in list(itertools.combinations(range(len(means)), 2)):\n",
    "                total_pairs += 1\n",
    "                if np.sign(true_means[i] - true_means[j]) == np.sign(means[i] - means[j]):\n",
    "                    correct_pairs += 1\n",
    "        \n",
    "            acc = correct_pairs / total_pairs\n",
    "            data.append(acc)\n",
    "        ys.append((np.mean(data), np.median(data), np.percentile(data, 0.05), np.percentile(data, 0.95)))\n",
    "    \n",
    "    return ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt19 = pickle.load(open('../wmt16-19-metrics-shared-task/wmt_metadata/pickles/wmt19_sys_metadata.pkl', 'rb'))\n",
    "wmt19.lp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_vars_toen = json.load(open('./data/vars/pooled_vars_toen.json'))\n",
    "total_vars_toen = json.load(open('./data/vars/total_vars_toen.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_var, total_var = pooled_vars_toen['wmt19'], total_vars_toen['wmt19']\n",
    "true_var = total_var - pooled_var\n",
    "ratio = total_var / true_var\n",
    "\n",
    "print(ratio)     # using x(ratio) more data is theoretical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_scores = pd.read_csv('./indexes.tsv', sep='\\t', index_col=[0])\n",
    "read_scores = lambda x: [ float(i.strip()) for i in list(open(x)) ]\n",
    "metric_scores['sentbleu'] = read_scores('./scores/sentbleu_scores')\n",
    "metric_scores['bleurt'] = read_scores('./scores/bleurt-base-128_scores')\n",
    "metric_scores['bleurt'] = read_scores('./scores/bleurt-base-128_scores')\n",
    "metric_scores['bert_score'] = [ float(i.split('\\t')[2]) for i in list(open('./scores/score_bert-score'))[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WMT2019 (*-en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIALS=1000\n",
    "all_ys = {}\n",
    "for lp in wmt19.lp.unique():\n",
    "    if not lp.endswith('en'):\n",
    "        continue\n",
    "\n",
    "    print(lp)\n",
    "    df_lp =  wmt19[(wmt19.lp == lp) & (wmt19.type.isin(['SYSTEM', 'REPEAT']))]\n",
    "    true = [ group.mean()['score'] for i, group in df_lp.groupby('system') ]\n",
    "\n",
    "    \n",
    "    xs = np.linspace(df_lp.groupby('system').count().min()['score'] / ratio, 0, 10, endpoint=False).astype(int)\n",
    "\n",
    "    ys = {}\n",
    "    try:\n",
    "        os.makedirs('cache/pairwise/%s' % lp)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    ys['human'] = cache('cache/pairwise/%s/y_human.json' % lp, lambda : generate(xs, df_lp[['system', 'score']], true, trials=TRIALS))\n",
    "    ys['theoretical'] = cache('cache/pairwise/%s/y_theoretical.json' % lp, lambda : generate(xs, df_lp[['system', 'score']], true, trials=TRIALS, ratio=ratio))\n",
    "\n",
    "    metric_scores_lp = metric_scores[metric_scores.lp == lp]\n",
    "    ys['bleurt'] = cache('cache/pairwise/%s/y_bleurt.json' % lp, lambda : generate(xs, metric_scores_lp[['system', 'bleurt']], true, score_name='bleurt', trials=TRIALS))\n",
    "    ys['sentbleu'] = cache('cache/pairwise/%s/y_sentbleu.json' % lp, lambda : generate(xs, metric_scores_lp[['system', 'sentbleu']], true, score_name='sentbleu', trials=TRIALS))\n",
    "    ys['bert_score'] = cache('cache/pairwise/%s/y_bert_score.json'% lp, lambda : generate(xs, metric_scores_lp[['system', 'bert_score']], true, score_name='bert_score', trials=TRIALS))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(lp)\n",
    "    for k, v in ys.items():\n",
    "        sns.lineplot(x=xs, y=[i[0] for i in v], label=k)\n",
    "    plt.savefig('figs/pairwise/%s.png' % lp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
