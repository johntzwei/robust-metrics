{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WMT16 and WMT17 segment-level data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt16 = pickle.load(open('../wmt16-19-metrics-shared-task/data/pickles/wmt16-seg_level-agg.pkl', 'rb'))\n",
    "wmt16['year'] = len(wmt16)*[2016]\n",
    "\n",
    "wmt17 = pickle.load(open('../wmt16-19-metrics-shared-task/data/pickles/wmt17-seg_level-agg.pkl', 'rb'))\n",
    "wmt17['year'] = len(wmt17)*[2017]\n",
    "\n",
    "wmt_mst_seg = pd.concat([wmt16, wmt17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lp</th>\n",
       "      <th>system</th>\n",
       "      <th>sid</th>\n",
       "      <th>sentBLEU</th>\n",
       "      <th>score</th>\n",
       "      <th>output</th>\n",
       "      <th>reference</th>\n",
       "      <th>source</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en-ru</td>\n",
       "      <td>jhu-pbmt</td>\n",
       "      <td>1092</td>\n",
       "      <td>0.273012</td>\n",
       "      <td>0.363122</td>\n",
       "      <td>43 закусочных нарушил требования к организации...</td>\n",
       "      <td>43 закусочных нарушили требования к устройству...</td>\n",
       "      <td>43 eateries violated requirements for the orga...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en-ru</td>\n",
       "      <td>online-G</td>\n",
       "      <td>750</td>\n",
       "      <td>0.076668</td>\n",
       "      <td>-0.450232</td>\n",
       "      <td>Учитывая, что он представляет собой сугубо пра...</td>\n",
       "      <td>Кажется маловероятным, что Кэмерон, будучи, по...</td>\n",
       "      <td>Given he is an avowedly hands-on parent, it se...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en-ru</td>\n",
       "      <td>AFRL-MITLL-phrase-based</td>\n",
       "      <td>2786</td>\n",
       "      <td>0.252464</td>\n",
       "      <td>0.113451</td>\n",
       "      <td>Печать процессы глобализации должны помогли ум...</td>\n",
       "      <td>Распечатать Процессы глобализации должны были ...</td>\n",
       "      <td>Printing the Processes of Globalisation should...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en-ru</td>\n",
       "      <td>LIMSI</td>\n",
       "      <td>250</td>\n",
       "      <td>0.531697</td>\n",
       "      <td>-0.257524</td>\n",
       "      <td>Это нечто значительное, странное или необычное...</td>\n",
       "      <td>Что-то важное, странное или необычное происход...</td>\n",
       "      <td>Is something significant, bizarre or unusual h...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en-ru</td>\n",
       "      <td>AFRL-MITLL-phrase-based</td>\n",
       "      <td>88</td>\n",
       "      <td>0.097414</td>\n",
       "      <td>-0.695001</td>\n",
       "      <td>В то время как сами праздничные дни месяца, в ...</td>\n",
       "      <td>Хотя до праздников еще несколько месяцев, сезо...</td>\n",
       "      <td>While the holidays themselves are months away,...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lp                   system   sid  sentBLEU     score  \\\n",
       "0  en-ru                 jhu-pbmt  1092  0.273012  0.363122   \n",
       "1  en-ru                 online-G   750  0.076668 -0.450232   \n",
       "2  en-ru  AFRL-MITLL-phrase-based  2786  0.252464  0.113451   \n",
       "3  en-ru                    LIMSI   250  0.531697 -0.257524   \n",
       "4  en-ru  AFRL-MITLL-phrase-based    88  0.097414 -0.695001   \n",
       "\n",
       "                                              output  \\\n",
       "0  43 закусочных нарушил требования к организации...   \n",
       "1  Учитывая, что он представляет собой сугубо пра...   \n",
       "2  Печать процессы глобализации должны помогли ум...   \n",
       "3  Это нечто значительное, странное или необычное...   \n",
       "4  В то время как сами праздничные дни месяца, в ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  43 закусочных нарушили требования к устройству...   \n",
       "1  Кажется маловероятным, что Кэмерон, будучи, по...   \n",
       "2  Распечатать Процессы глобализации должны были ...   \n",
       "3  Что-то важное, странное или необычное происход...   \n",
       "4  Хотя до праздников еще несколько месяцев, сезо...   \n",
       "\n",
       "                                              source  year  \n",
       "0  43 eateries violated requirements for the orga...  2016  \n",
       "1  Given he is an avowedly hands-on parent, it se...  2016  \n",
       "2  Printing the Processes of Globalisation should...  2016  \n",
       "3  Is something significant, bizarre or unusual h...  2016  \n",
       "4  While the holidays themselves are months away,...  2016  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmt_mst_seg.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is about tolerance , acceptance and the vision of an open society .\n",
      "It is a matter of tolerance , acceptance and the Vision of an open society .\n"
     ]
    }
   ],
   "source": [
    "reference = word_tokenize(wmt_mst_seg[wmt_mst_seg.lp == 'de-en'].iloc[10]['reference'])\n",
    "hypothesis = word_tokenize(wmt_mst_seg[wmt_mst_seg.lp == 'de-en'].iloc[10]['output'])\n",
    "print(' '.join(reference))\n",
    "print(' '.join(hypothesis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permuting chunks defined by bigram mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4935578819979932"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu([reference], hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(reference, hypothesis):\n",
    "    s = set(bigrams(reference))\n",
    "    \n",
    "    match = []\n",
    "    for idx, bg in enumerate(zip(hypothesis, hypothesis[1:])):\n",
    "        match.append(bg in s)\n",
    "    \n",
    "    segments = [[hypothesis[0]]]\n",
    "    \n",
    "    for idx, b in enumerate(match[:-1]):\n",
    "        if match[idx] == match[idx+1]:\n",
    "            segments[-1].append(hypothesis[idx+1])\n",
    "        else:\n",
    "            if match[idx]:\n",
    "                segments[-1].append(hypothesis[idx+1])\n",
    "                segments.append([])\n",
    "            else:\n",
    "                segments.append([])\n",
    "                segments[-1].append(hypothesis[idx+1])\n",
    "    segments[-1].append(hypothesis[-1])\n",
    "        \n",
    "    return segments\n",
    "\n",
    "def permute_chunks(segments):\n",
    "    return sorted(segments, key=lambda x: random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['It', 'is'], ['a', 'matter', 'of'], ['tolerance', ',', 'acceptance', 'and', 'the'], ['Vision'], ['of', 'an', 'open', 'society', '.']]\n",
      "\n",
      "Vision a matter of of an open society . It is tolerance , acceptance and the\n"
     ]
    }
   ],
   "source": [
    "segments = chunks(reference, hypothesis)\n",
    "print(segments)\n",
    "adv_hypothesis = sum(permute_chunks(segments), [])\n",
    "print()\n",
    "print(' '.join(adv_hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4935578819979932"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu([reference], adv_hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substituting words that do not overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlapping(reference, hypothesis):\n",
    "    overlap = []\n",
    "    for i in hypothesis:\n",
    "        overlap.append(i in reference)\n",
    "    return overlap\n",
    "\n",
    "def random_replace(reference, hypothesis, overlap, replace_prob=0.5, replacement_func=lambda x: 'WORD'):\n",
    "    adv_hypothesis = hypothesis.copy()\n",
    "    for i, ol in enumerate(overlap):\n",
    "        if not ol:\n",
    "            if random.random() < replace_prob:\n",
    "                adv_hypothesis[i] = replacement_func(hypothesis[i])\n",
    "    return adv_hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'good', 'prank', 'is', 'funny', ',', 'but', 'WORD', 'takes', 'WORD', 'moments', 'WORD', 'WORD', 'WORD', 'WORD', 'WORD', '.']\n"
     ]
    }
   ],
   "source": [
    "overlap = overlapping(reference, hypothesis)\n",
    "adv_hypothesis = random_replace(reference, hypothesis, overlap, 1)\n",
    "print(adv_hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3807134866446316"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu([reference], adv_hypothesis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
